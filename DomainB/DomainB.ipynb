{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"3oncEwJC9T07"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torch.optim as optim\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","from tqdm import tqdm\n","from torchvision import datasets\n","from torch.utils.data import DataLoader\n","from torchvision.utils import save_image\n","from torch.autograd import Variable\n","import numpy as np\n","import PIL\n","import pandas as pd\n","matplotlib.style.use('ggplot')\n","torch.cuda.empty_cache()\n","import os \n","import random\n","\n","def set_seed(seed):\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    # cudnn.deterministic = True\n","    # cudnn.benchmark = False\n","\n","set_seed(1234)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"l3aXNo6QhU2O"},"outputs":[],"source":["class Dataset(object):\n","    \n","    def __getitem__(self, index):\n","        raise NotImplementedError\n","\n","    def __len__(self):\n","        raise NotImplementedError\n","\n","    def __add__(self, other):\n","        return ConcatDataset([self, other])\n","\n","class DatasetMNIST(Dataset):\n","    \n","    def __init__(self, file_path, transform=None):\n","        self.data = pd.read_csv(file_path)\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, index):\n","\n","        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28, 28, 1))\n","        label = self.data.iloc[index, 0]\n","        \n","        if self.transform is not None:\n","            image = self.transform(image)\n","            \n","        return image, label\n","\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((64,64)),\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.ToTensor(),\n","])\n","\n","\n","train_data = DatasetMNIST('/home/ubuntu/Latent-Transfer/DomainB/DomainB_dataset/sign_mnist_train.csv', transform = transform)\n","test_data = DatasetMNIST('/home/ubuntu/Latent-Transfer/DomainB/DomainB_dataset/sign_mnist_test.csv', transform = transform)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1635925752850,"user":{"displayName":"Vignesh S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11315277004586324186"},"user_tz":-330},"id":"I2e0NvV2ss07","outputId":"f2d0f3f6-f7fa-4345-b2bb-2fe0d9c4600e"},"outputs":[{"data":{"text/plain":["torch.Size([1, 64, 64])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["img, label = train_data[0]\n","img.shape"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"20lY0Rb_HzTx"},"outputs":[],"source":["num_epochs = 300\n","batch_size = 64\n","learning_rate = 1e-4\n","\n","\n","# train_loader_1s1c = DataLoader(\n","#     train_data_1s1c,\n","#     batch_size=batch_size,\n","#     shuffle=True\n","# )\n","\n","# train_loader_1s26c = DataLoader(\n","#     train_data_1s26c,\n","#     batch_size=batch_size,\n","#     shuffle=True\n","# )\n","# train_loader_Ms1c = DataLoader(\n","#     train_data_Ms1c,\n","#     batch_size=batch_size,\n","#     shuffle=True\n","# )\n","\n","train_loader = DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","setting = ''\n","dataloader = train_loader"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18501,"status":"ok","timestamp":1635925771347,"user":{"displayName":"Vignesh S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11315277004586324186"},"user_tz":-330},"id":"Un7YslQWMVU_","outputId":"61b024c2-16d1-4438-e489-f82f009dbcd2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/miniconda3/envs/latent/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","/home/ubuntu/miniconda3/envs/latent/lib/python3.7/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"]},{"name":"stdout","output_type":"stream","text":["Train Epoch: 1 [0/27455 (0%)]\tLoss: 316.504669\n","Train Epoch: 1 [6400/27455 (23%)]\tLoss: 89.438461\n","Train Epoch: 1 [12800/27455 (47%)]\tLoss: 82.498627\n","Train Epoch: 1 [19200/27455 (70%)]\tLoss: 77.073174\n","Train Epoch: 1 [25600/27455 (93%)]\tLoss: 75.490242\n","====> Epoch: 0 Average loss: 91.5137\n","Train Epoch: 2 [0/27455 (0%)]\tLoss: 70.004196\n","Train Epoch: 2 [6400/27455 (23%)]\tLoss: 68.025421\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2067/4030875300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/latent/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/latent/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def to_img(x):\n","    x = x.clamp(0, 1)\n","    x = x.view(x.size(0), 1, 64, 64)\n","    return x\n","\n","\n","class CvBlock(nn.Module):\n","    \"\"\"(Conv2d => BN => ReLU) x 2\"\"\"\n","\n","    def __init__(self, in_ch, out_ch):\n","        super(CvBlock, self).__init__()\n","        self.convblock = nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.convblock(x)\n","\n","\n","class DownBlock(nn.Module):\n","    \"\"\"Downscale + (Conv2d => BN => ReLU)*2\"\"\"\n","\n","    def __init__(self, in_ch, out_ch):\n","        super(DownBlock, self).__init__()\n","        self.convblock = nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, stride=2),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","            CvBlock(out_ch, out_ch),\n","        )\n","\n","    def forward(self, x):\n","      \n","        return self.convblock(x)\n","\n","\n","class UpBlock(nn.Module):\n","    \"\"\"(Conv2d => BN => ReLU)*2 + Upscale\"\"\"\n","\n","    def __init__(self, in_ch, out_ch):\n","        super(UpBlock, self).__init__()\n","        self.convblock = nn.Sequential(\n","            CvBlock(in_ch, in_ch),\n","            nn.Conv2d(in_ch, out_ch * 4, kernel_size=3, padding=1),\n","            nn.PixelShuffle(2),\n","        )\n","\n","    def forward(self, x):\n","\n","        return self.convblock(x)\n","\n","\n","class Reshape(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","        self.shape = args\n","\n","    def forward(self, x):\n","        return x.view(self.shape)\n","\n","\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","\n","        self.encoder = nn.Sequential(\n","            DownBlock(1, 32),\n","            DownBlock(32, 64),\n","            DownBlock(64, 128),\n","            DownBlock(128, 256),\n","            nn.Flatten(),\n","        )\n","        self.z_mean = nn.Linear(4096, 256)\n","        self.z_var = nn.Linear(4096, 256)\n","        self.z_up = nn.Linear(256, 4096)\n","        self.decoder = nn.Sequential(\n","            nn.Linear(256,4096),\n","            Reshape(-1, 256, 4, 4),\n","            UpBlock(256, 128),\n","            UpBlock(128, 64),\n","            UpBlock(64, 32),\n","            UpBlock(32, 1),\n","        )\n","\n","    def encode(self, x):\n","        h1 = self.encoder(x)\n","    \n","        return self.z_mean(h1), self.z_var(h1)\n","\n","    @staticmethod\n","    def reparametrize(mu, logvar):\n","        std = logvar.mul(0.5).exp_()\n","        if torch.cuda.is_available():\n","            eps = torch.cuda.FloatTensor(std.size()).normal_()\n","        else:\n","            eps = torch.FloatTensor(std.size()).normal_()\n","        eps = Variable(eps)\n","        return eps.mul(std).add_(mu)\n","\n","    def decode(self, z):\n","\n","        h3 = self.decoder(z)\n","        return F.sigmoid(h3)\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        # print(mu.shape, logvar.shape)\n","        z = self.reparametrize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","\n","model = VAE()\n","if torch.cuda.is_available():\n","    model.cuda()\n","\n","reconstruction_function = nn.MSELoss(size_average=False)\n","\n","\n","def loss_function(recon_x, x, mu, logvar):\n","    \"\"\"\n","    recon_x: generating images\n","    x: origin images\n","    mu: latent mean\n","    logvar: latent log variance\n","    \"\"\"\n","    \n","    BCE = reconstruction_function(recon_x, x)    \n","    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n","    KLD = torch.sum(KLD_element).mul_(-0.5)\n","    return BCE + KLD\n","\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0\n","    for batch_idx, data in enumerate(dataloader):\n","        img, _ = data\n","        \n","        img = Variable(img)\n","        if torch.cuda.is_available():\n","            img = img.cuda()\n","        optimizer.zero_grad()\n","        recon_batch, mu, logvar = model(img)\n","        loss = loss_function(recon_batch, img, mu, logvar)\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            print(\n","                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n","                    epoch + 1,\n","                    batch_idx * len(img),\n","                    len(dataloader.dataset),\n","                    100.0 * batch_idx / len(dataloader),\n","                    loss.item() / len(img),\n","                )\n","            )\n","\n","    print(\"====> Epoch: {} Average loss: {:.4f}\".format(epoch+1, train_loss / len(dataloader.dataset)))\n","    if epoch % 10 == 0:\n","        save = to_img(recon_batch.cpu().data)\n","        save_image(save, \"/home/ubuntu/Latent-Transfer/DomainB/outputs/models/image_{}.png\".format(epoch+1))\n","        torch.save(model.state_dict(), \"/home/ubuntu/Latent-Transfer/DomainB/outputs/models/cnn_vae_{}.pth\".format(epoch+1))\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"DomainB.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}
